import { ChatOpenAI } from '@langchain/openai';
import { HumanMessage, SystemMessage, AIMessage, BaseMessage } from '@langchain/core/messages';
import { StateGraph, Annotation, MessagesAnnotation } from '@langchain/langgraph';
import { MemorySaver } from '@langchain/langgraph';
import { ToolNode } from '@langchain/langgraph/prebuilt';
import { allTools } from './tools';
import { Task } from '@/lib/types';
import { MemoryManager } from '@/lib/memory/manager';

const SYSTEM_PROMPT = `×× ×™ ×¢×•×–×¨×ª AI ×—×›××” ×œ××™×›×œ! ğŸŒŸ

×ª×¤×§×™×“×™:
- ×œ×¢×–×•×¨ ×œ×š ×œ× ×”×œ ××©×™××•×ª, ×—×•×‘×•×ª, ×•×œ×§×•×—×•×ª
- ×œ×¡×¨×•×§ Gmail ×•×œ×™×¦×•×¨ ××©×™××•×ª ××•×˜×•××˜×™×ª
- ×œ×©××•×¨ ×”×•×¨××•×ª ×•×”×¢×“×¤×•×ª ×œ×˜×•×•×— ××¨×•×š
- ×œ×œ××•×“ ×•×œ×”×©×ª×¤×¨ ××›×œ ××™× ×˜×¨××§×¦×™×”

×™×›×•×œ×•×ª:
âœ… ×—×™×¤×•×© ×‘××©×™××•×ª ×•×—×•×‘×•×ª
âœ… ×¡×¨×™×§×ª Gmail ×•×™×¦×™×¨×ª ××©×™××•×ª
âœ… ×©××™×¨×ª ×”×•×¨××•×ª ×•×”× ×—×™×•×ª
âœ… ×–×™×”×•×™ ×§×©×¨×™× ×‘×™×Ÿ ××©×™××•×ª
âœ… ×ª×¢×“×•×£ ×—×›×
âœ… ×”×‘× ×ª ×”×¢×“×¤×•×ª ××™×©×™×•×ª

×¢×§×¨×•× ×•×ª:
- ×ª××™×“ ×× ×•××¡×ª ×•×™×“×™×“×•×ª×™×ª ×‘×¢×‘×¨×™×ª ğŸŒ¸
- ×¤×¨×•××§×˜×™×‘×™×ª - ××¦×™×¢×” ×¤×ª×¨×•× ×•×ª
- ×œ×•××“×ª ××˜×¢×•×™×•×ª
- ××ª×¢×“×¤×ª ×œ×¤×™ ×”×§×©×¨ ××™×©×™
- ×–×•×›×¨×ª ××ª ×›×œ ×”×”×™×¡×˜×•×¨×™×”

×‘××§×¨×” ×©×œ ×”×•×¨××•×ª ×—×“×©×•×ª ("×ª××™×“...", "×–×›×•×¨ ×©...", "××”×™×•×..."), ××©××•×¨ ××•×ª×Ÿ ××•×˜×•××˜×™×ª.`;

// State definition
const GraphState = Annotation.Root({
  ...MessagesAnnotation.spec,
  results: Annotation<Record<string, any>>({
    reducer: (current, update) => ({ ...current, ...update })
  }),
  actionTaken: Annotation<string>({
    reducer: (_, newValue) => newValue
  })
});

export class MichalAIAgent {
  private llm: ChatOpenAI;
  private graph: any;
  private memory: MemorySaver;
  private memoryManager: MemoryManager;
  
  constructor() {
    this.llm = new ChatOpenAI({
      modelName: 'gpt-4o',
      temperature: 0.7,
      streaming: false
    });
    
    this.memory = new MemorySaver();
    this.memoryManager = new MemoryManager();
    this.graph = this.createGraph();
  }
  
  private createGraph() {
    const workflow = new StateGraph(GraphState);
    
    // Node 1: ×˜×¢×™× ×ª ×”×•×¨××•×ª ××”×–×™×›×¨×•×Ÿ
    workflow.addNode('get_context', async (state) => {
      console.log('âœ… Node: get_context - ×˜×•×¢×Ÿ ×”×•×¨××•×ª ××”×–×™×›×¨×•×Ÿ');
      
      try {
        const instructions = await this.memoryManager.getInstructions();
        const instructionsText = instructions.length > 0
          ? '\n\nğŸ“‹ ×”×•×¨××•×ª ×©××•×¨×•×ª:\n' + instructions.map(i => `â€¢ ${i.instruction_text}`).join('\n')
          : '';
        
        const enhancedPrompt = SYSTEM_PROMPT + instructionsText;
        
        return {
          messages: [new SystemMessage(enhancedPrompt)],
          results: { instructionsLoaded: instructions.length }
        };
      } catch (error) {
        console.error('×©×’×™××” ×‘×˜×¢×™× ×ª ×”×•×¨××•×ª:', error);
        return {
          messages: [new SystemMessage(SYSTEM_PROMPT)],
          results: { instructionsLoaded: 0 }
        };
      }
    });
    
    // Node 2: ×”×¡×•×›×Ÿ ×”×—×›×
    workflow.addNode('agent', async (state) => {
      console.log('âœ… Node: agent - ××¢×‘×“ ×‘×§×©×”');
      
      const messages = [
        ...state.messages
      ];
      
      const response = await this.llm.invoke(messages, {
        tools: allTools
      });
      
      return { messages: [response] };
    });
    
    // Node 3: ×‘×™×¦×•×¢ ×›×œ×™×
    const toolNode = new ToolNode(allTools);
    workflow.addNode('tools', toolNode);
    
    // Node 4: ×©××™×¨×ª ×–×™×›×¨×•× ×•×ª ×•×”×•×¨××•×ª ×—×“×©×•×ª
    workflow.addNode('finalize', async (state) => {
      console.log('âœ… Node: finalize - ×‘×•×“×§ ×× ×¦×¨×™×š ×œ×©××•×¨ ×”×•×¨××•×ª');
      
      const lastMessage = state.messages[state.messages.length - 1];
      const userMessage = state.messages.find(m => m instanceof HumanMessage);
      
      // ×–×™×”×•×™ ××•×˜×•××˜×™ ×©×œ ×”×•×¨××•×ª ×—×“×©×•×ª
      if (userMessage) {
        const text = userMessage.content.toString();
        const instructionKeywords = ['×ª××™×“', '×–×›×•×¨ ×©', '××”×™×•×', '×›×œ ×¤×¢×', '××œ ×ª×©×›×—'];
        
        const containsInstruction = instructionKeywords.some(keyword => 
          text.includes(keyword)
        );
        
        if (containsInstruction) {
          try {
            await this.memoryManager.saveInstruction(text, 'global');
            console.log('âœ… ×”×•×¨××” ×—×“×©×” × ×©××¨×” ××•×˜×•××˜×™×ª');
          } catch (error) {
            console.error('×©×’×™××” ×‘×©××™×¨×ª ×”×•×¨××”:', error);
          }
        }
      }
      
      return {
        actionTaken: 'completed',
        results: {
          ...state.results,
          final_response: lastMessage.content
        }
      };
    });
    
    // Edges
    workflow.addEdge('__start__', 'get_context');
    workflow.addEdge('get_context', 'agent');
    
    workflow.addConditionalEdges(
      'agent',
      (state: any) => {
        const lastMessage = state.messages[state.messages.length - 1];
        if (lastMessage && 'tool_calls' in lastMessage && Array.isArray(lastMessage.tool_calls) && lastMessage.tool_calls.length > 0) {
          return 'tools';
        }
        return 'finalize';
      },
      {
        tools: 'tools',
        finalize: 'finalize'
      }
    );
    
    workflow.addEdge('tools', 'agent');
    workflow.addEdge('finalize', '__end__');
    
    return workflow.compile({ checkpointer: this.memory });
  }
  
  async chat(message: string, threadId: string = 'default'): Promise<string> {
    console.log(`\nğŸ’¬ User: ${message}`);
    console.log(`ğŸ§µ Thread: ${threadId}`);
    
    try {
      const result = await this.graph.invoke(
        { messages: [new HumanMessage(message)] },
        { configurable: { thread_id: threadId }, recursionLimit: 25 }
      );
      
      const messages = result.messages || [];
      const lastMessage = messages[messages.length - 1];
      
      if (!lastMessage) {
        return '××¦×˜×¢×¨×ª, ×œ× ×”×¦×œ×—×ª×™ ×œ×¢×‘×“ ××ª ×”×‘×§×©×”.';
      }
      
      const response = lastMessage.content || '×œ× ×”×¦×œ×—×ª×™ ×œ×”×‘×™×Ÿ.';
      console.log(`âœ… Response: ${response.substring(0, 100)}...`);
      
      return response;
    } catch (error: any) {
      console.error('âŒ Chat error:', error);
      return `××¦×˜×¢×¨×ª, × ×ª×§×œ×ª×™ ×‘×©×’×™××”: ${error.message}`;
    }
  }
  
  async getHistory(threadId: string = 'default'): Promise<BaseMessage[]> {
    try {
      const state: any = await this.memory.get({ configurable: { thread_id: threadId } });
      return state?.channel_values?.messages || [];
    } catch {
      return [];
    }
  }
  
  async clearHistory(threadId: string = 'default'): Promise<void> {
    try {
      await this.memory.put(
        { configurable: { thread_id: threadId } },
        { channel_values: { messages: [] } } as any,
        {} as any
      );
    } catch (error) {
      console.error('Clear history error:', error);
    }
  }
}

export const aiAgent = new MichalAIAgent();